{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pytz\n",
    "import re\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, matthews_corrcoef\n",
    "from joblib import dump, load\n",
    "from text_unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw data\n",
    "=======\n",
    "\n",
    "Define directory where the data is loacated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_raw_data = \"C:/Users/danie/Documents/Research Data/Project data/Data Project Sentiment Race/00_raw/\"\n",
    "dir_original_data = 'C:/Users/danie/Documents/Research Data/Original data/StockTwits SP500/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data issues\n",
    "Load file that summarise the issues with the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_issue = pd.read_csv(\n",
    "    dir_raw_data + 'data_issue_info.tsv', \n",
    "    delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_excluded = data_issue.loc[data_issue['exclude']==1, 'rpid'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping file\n",
    "Load mapping file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_mapping = pd.read_csv(\n",
    "    dir_raw_data + \"SP500_Company_Mapping.tsv\",\n",
    "    delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lowercase company's ticker and name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_mapping['taq_ticker'] = company_mapping['taq_ticker'].map(lambda ticker: ticker.lower())\n",
    "company_mapping['original_name'] = company_mapping['original_name'].map(lambda name: name.lower())\n",
    "company_mapping['cleaned_name'] = company_mapping['cleaned_name'].map(lambda name: name.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove observations for which we have data issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = company_mapping['rpid'].map(lambda x: x in to_be_excluded)\n",
    "company_mapping = company_mapping.loc[~to_remove, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emoticons\n",
    "Load emoticons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis = pd.read_csv(dir_raw_data + 'emojis.csv', delimiter=';', index_col='unicode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load tagged emoticons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis_tags = pd.read_csv(dir_raw_data + 'emojis_tags.csv', delimiter=';', index_col='unicode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define regular expressions for positive and negative emoticons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis_positive = '|'.join('(' + pd.concat([emojis_tags.loc[emojis_tags['tag'] == 'positive'], emojis],\n",
    "                                           join='inner', axis=1)['ftu8'] + ')')\n",
    "emojis_negative = '|'.join('(' + pd.concat([emojis_tags.loc[emojis_tags['tag'] == 'negative'], emojis],\n",
    "                                           join='inner', axis=1)['ftu8'] + ')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text cleaning function\n",
    "Define function that cleans the text of each tweet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, regex_cashtag, regex_ticker, regex_name, regex_cleanname, regex_posemoji, regex_negemoji, lemmer):\n",
    "    # Transform text to unicode:\n",
    "    text = unidecode(text)\n",
    "    # Replace positive emojis:\n",
    "    text = re.sub(regex_posemoji, ' emojipostag ', text)\n",
    "    text = re.sub('(:[)])|(;[)])|(:-[)])|(=[)])|(:D)', ' emojipostag ', text)\n",
    "    # Replace negative emojis:\n",
    "    text = re.sub(regex_negemoji, ' emojinegtag ', text)\n",
    "    text = re.sub('(:[(])|(:-[(])|(=[(])', ' emojinegtag ', text)\n",
    "    # Remove other emojis:\n",
    "    text = re.sub('[<][a-z0-9]+[>]', ' ', text)\n",
    "    # Remove HTML tags:\n",
    "    cleanhtml = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "    text = re.sub(cleanhtml, '', text)\n",
    "    # Change encoding to remove non-english words\n",
    "    text = text.encode(\"ascii\", errors=\"ignore\").decode()\n",
    "    # Lower case all letters\n",
    "    text = text.lower()\n",
    "    # Remove \"'s\"\n",
    "    text = re.sub(r\"'s(?=\\s)\", ' ', text)\n",
    "    # Replace usernames with \"usernametag\"\n",
    "    text = re.sub(r'[@]\\w+(?=\\s|$)', ' usernametag ', text)\n",
    "    # Replace Twitter picuters with picturetag\n",
    "    text = re.sub(r'pic.twitter.com/[0-9a-zA-Z]*(?=\\s|$)', ' picturetag ', text)\n",
    "    # Replace URLs with \"urltag\"\n",
    "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' urltag ', text)\n",
    "    # Replace Q1 with first quarter tag:\n",
    "    text = re.sub('q1', ' firstquartertag ', text)\n",
    "    # Replace Q2 with first quarter tag:\n",
    "    text = re.sub('q2', ' secondquartertag ', text)\n",
    "    # Replace Q3 with first quarter tag:\n",
    "    text = re.sub('q3', ' thirdquartertag ', text)\n",
    "    # Replace Q4 with first quarter tag:\n",
    "    text = re.sub('q4', ' fourthquartertag ', text)\n",
    "    # Replace percent numbers with tag:\n",
    "    text = re.sub(r'([+-]*\\d+[.,:]\\d+[%])|([+-]*\\d+[%])', ' numbertag ', text)\n",
    "    # Replace numbers with tag:\n",
    "    text = re.sub(r'([+-]*\\d+[.,:]\\d+)|([+-]*\\d+)', ' numbertag ', text)\n",
    "    # Replace company cashtag\n",
    "    text = re.sub(regex_cashtag, ' companycashtag ', text)\n",
    "    # Replace company ticker\n",
    "    text = re.sub(regex_ticker, ' companytickertag ', text)\n",
    "    # Replace all other cashtags with a tag\n",
    "    text = re.sub(r'[$]\\b[a-zA-z]+\\b', ' cashtag ', text)\n",
    "    # Replace company name with tag:\n",
    "    text = re.sub(regex_name, ' companynametag ', text)\n",
    "    text = re.sub(regex_cleanname, ' companynametag ', text)\n",
    "    # Characters that appear more two or more times are shortened (e.g. loooool -> lool):\n",
    "    text = re.sub(r'(\\w)\\1{2,}', r'\\1\\1', text)\n",
    "    # Remove remaining punctuation\n",
    "    text = re.sub('['+string.punctuation+']', ' ', text)\n",
    "    # Remove double spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Lemmatize text:\n",
    "    text = ' '.join([lemmer.lemmatize(word) for word in text.split(' ')])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the lemmatizer need for the cleaning function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load tweets\n",
    "Load and clean tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweets = pd.DataFrame()\n",
    "for rpid_i in company_mapping['rpid'].unique():\n",
    "    # Load data for the company with ID 'rpid_i':\n",
    "    data_i = pd.read_csv(\n",
    "        dir_original_data + rpid_i + '_tweets.tsv',\n",
    "        encoding=\"ANSI\", quotechar='\"', delimiter=\"\\t\", engine='python')\n",
    "    # Keep only observations which have been classified by users:\n",
    "    data_i = data_i.loc[data_i['StockTwits_sentiment'] != 'None', ['StockTwits_sentiment', 'text', 'tweet_datetime']]\n",
    "    # Define regular expression for the company's cashtag:\n",
    "    cashtag_regex_i = '|'.join(r'([$]{1}\\b' + company_mapping.loc[company_mapping['rpid'] == rpid_i, 'taq_ticker'] + r'\\b)')\n",
    "    ticker_regex_i = '|'.join(r'(\\b' + company_mapping.loc[company_mapping['rpid'] == rpid_i, 'taq_ticker'] + r'\\b)')\n",
    "    # Define regular expression for the company's name:\n",
    "    name_regex_i = '|'.join(r'(\\b' + company_mapping.loc[company_mapping['rpid'] == rpid_i, 'original_name'] + r'\\b)')\n",
    "    nameclean_regex_i = '|'.join(r'(\\b' + company_mapping.loc[company_mapping['rpid'] == rpid_i, 'cleaned_name'] + r'\\b)')\n",
    "    # Clean text data:\n",
    "    data_i['text'] = data_i['text'].map(lambda x: clean_text(x,\n",
    "                                                             cashtag_regex_i,\n",
    "                                                             ticker_regex_i,\n",
    "                                                             name_regex_i,\n",
    "                                                             nameclean_regex_i,\n",
    "                                                             emojis_positive,\n",
    "                                                             emojis_negative,\n",
    "                                                             lemmer))\n",
    "    # Add RavenPack ID:\n",
    "    data_i['rpid'] = rpid_i\n",
    "    # Append data:\n",
    "    data_tweets = data_tweets.append(data_i, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert string to datetime-object and add New York time zone (Eastern time):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tz_utc = pytz.timezone('UTC')\n",
    "tz_NY = pytz.timezone('America/New_York')\n",
    "data_tweets['tweet_datetime'] = data_tweets['tweet_datetime'].map(lambda x: pd.Timestamp(x))\n",
    "data_tweets['tweet_datetime_ET'] = data_tweets['tweet_datetime'].map(lambda x: x.astimezone(tz_NY))\n",
    "data_tweets['tweet_date_ET'] = data_tweets['tweet_datetime_ET'].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature construction\n",
    "## Training and test set\n",
    "Define index of training observations. For consistency with [Renault (2017, JBF)](https://www.sciencedirect.com/science/article/abs/pii/S0378426617301589), the training period starts in June 2013 and ends in August 2014:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_date_range = pd.date_range(start=datetime.datetime(2013, 6, 1), end=datetime.datetime(2014, 8, 31))\n",
    "idx_train = data_tweets['tweet_date_ET'].map(lambda x: x in training_date_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target\n",
    "Define the outcome variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = preprocessing.LabelBinarizer()\n",
    "y_train = lb.fit_transform(data_tweets.loc[idx_train, 'StockTwits_sentiment'])\n",
    "y_test = lb.transform(data_tweets.loc[~idx_train, 'StockTwits_sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature construction\n",
    "Define different vectorizations of the text data.\n",
    "* Bag-of-words: consider uni- and bi-grams, only keep tokens which appear at least in 0.1% of the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_bow = CountVectorizer(stop_words=['a', 'an', 'the'], min_df=0.001, ngram_range=(1, 2))\n",
    "X_bow_train = vectorizer_bow.fit_transform(data_tweets.loc[idx_train, 'text'])\n",
    "X_bow_test = vectorizer_bow.transform(data_tweets.loc[~idx_train, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['able', 'about', 'about companycashtag', 'about numbertag', 'about to', 'above', 'above numbertag', 'ac', 'according', 'account', 'acquisition', 'acting', 'action', 'active', 'activity', 'actually', 'ad', 'add', 'add to', 'added', 'added to', 'adding', 'advice', 'aeur', 'after', 'after earnings', 'after er', 'after hour', 'after numbertag', 'afternoon', 'again', 'against', 'ago', 'agree', 'ah', 'ahead', 'ahead of', 'air', 'alert', 'all', 'all day', 'all in', 'all of', 'all time', 'almost', 'almost numbertag', 'aloha', 'along', 'along with', 'already', 'also', 'always', 'am', 'amazing', 'amazon', 'america', 'analysis', 'analyst', 'analyst rating', 'and', 'and buy', 'and cashtag', 'and companycashtag', 'and hold', 'and it', 'and more', 'and now', 'and numbertag', 'and then', 'and they', 'and this', 'and up', 'and we', 'and will', 'and you', 'android', 'announce', 'announced', 'announcement', 'another', 'another numbertag', 'any', 'anyone', 'anything', 'app', 'appl', 'apple', 'apr', 'apr numbertag', 'april', 'april numbertag', 'are', 'are all', 'are going', 'are in', 'are not', 'are positive', 'are you', 'area', 'aristocrat', 'around', 'around numbertag', 'article', 'ask', 'at', 'at all', 'at cashtag', 'at companycashtag', 'at least', 'at numbertag', 'at open', 'at these', 'at this', 'ath', 'attention', 'aug', 'aug numbertag', 'august', 'august numbertag', 'average', 'avg', 'away', 'awesome', 'baby', 'back', 'back in', 'back on', 'back to', 'back up', 'bad', 'bank', 'bar', 'bargain', 'base', 'based', 'based on', 'bb', 'bbry', 'be', 'be good', 'be in', 'be nice', 'be numbertag', 'be up', 'be very', 'bear', 'bearish', 'beast', 'beat', 'beautiful', 'because', 'because of', 'become', 'been', 'before', 'before earnings', 'before er', 'before it', 'begin', 'beginning', 'behind', 'being', 'believe', 'bell', 'below', 'below numbertag', 'benefit', 'best', 'best sentiment', 'bet', 'better', 'better than', 'between', 'between numbertag', 'bid', 'big', 'big boy', 'bigger', 'biggest', 'billion', 'biotech', 'bit', 'blackberry', 'block', 'blog', 'bloomberg', 'blow', 'blue', 'board', 'book', 'boom', 'boost', 'bot', 'both', 'bottom', 'bought', 'bought numbertag', 'bought some', 'bounce', 'box', 'boy', 'brainer', 'brand', 'break', 'break above', 'break numbertag', 'break of', 'break out', 'breakdown', 'breaking', 'breaking out', 'breakout', 'breakout urltag', 'bring', 'broke', 'broken', 'btmfd', 'bto', 'bubble', 'buck', 'building', 'bull', 'bull flag', 'bullish', 'bullish on', 'bullish urltag', 'business', 'but', 'but it', 'but not', 'but still', 'but this', 'buy', 'buy and', 'buy at', 'buy back', 'buy buy', 'buy cashtag', 'buy companycashtag', 'buy dip', 'buy it', 'buy more', 'buy now', 'buy numbertag', 'buy on', 'buy signal', 'buy this', 'buy urltag', 'buyback', 'buyer', 'buying', 'buying opportunity', 'buyout', 'by', 'by end', 'by friday', 'by numbertag', 'bye', 'ca', 'call', 'call and', 'call at', 'call for', 'call numbertag', 'call on', 'call option', 'call spread', 'called', 'calling', 'came', 'can', 'can be', 'can get', 'can see', 'candle', 'cannot', 'cant', 'cant wait', 'cap', 'capital', 'car', 'card', 'care', 'careful', 'carl', 'case', 'cash', 'cashtag', 'cashtag all', 'cashtag and', 'cashtag are', 'cashtag at', 'cashtag buy', 'cashtag cashtag', 'cashtag companycashtag', 'cashtag companynametag', 'cashtag for', 'cashtag ha', 'cashtag if', 'cashtag in', 'cashtag is', 'cashtag it', 'cashtag just', 'cashtag long', 'cashtag look', 'cashtag looking', 'cashtag more', 'cashtag not', 'cashtag numbertag', 'cashtag on', 'cashtag or', 'cashtag short', 'cashtag stock', 'cashtag this', 'cashtag to', 'cashtag today', 'cashtag up', 'cashtag urltag', 'cashtag will', 'cashtag with', 'catalyst', 'catch', 'cause', 'cc', 'cell', 'cent', 'ceo', 'chance', 'change', 'changed', 'channel', 'chart', 'chart look', 'chart urltag', 'cheap', 'cheaper', 'check', 'check out', 'cheer', 'china', 'china mobile', 'chinese', 'chip', 'chl', 'christmas', 'clear', 'climb', 'close', 'close above', 'close at', 'close to', 'closed', 'closing', 'cloud', 'cnbc', 'co', 'com', 'come', 'come back', 'come on', 'come out', 'coming', 'coming in', 'coming soon', 'comment', 'common', 'company', 'companycashtag', 'companycashtag about', 'companycashtag added', 'companycashtag after', 'companycashtag all', 'companycashtag am', 'companycashtag and', 'companycashtag another', 'companycashtag any', 'companycashtag anyone', 'companycashtag are', 'companycashtag at', 'companycashtag back', 'companycashtag bear', 'companycashtag bearish', 'companycashtag beat', 'companycashtag big', 'companycashtag boom', 'companycashtag bought', 'companycashtag break', 'companycashtag breaking', 'companycashtag breakout', 'companycashtag broke', 'companycashtag bull', 'companycashtag bullish', 'companycashtag but', 'companycashtag buy', 'companycashtag buying', 'companycashtag call', 'companycashtag can', 'companycashtag cant', 'companycashtag cashtag', 'companycashtag chart', 'companycashtag china', 'companycashtag close', 'companycashtag come', 'companycashtag companynametag', 'companycashtag companytickertag', 'companycashtag could', 'companycashtag daily', 'companycashtag did', 'companycashtag do', 'companycashtag doe', 'companycashtag dont', 'companycashtag down', 'companycashtag earnings', 'companycashtag finally', 'companycashtag for', 'companycashtag gap', 'companycashtag get', 'companycashtag getting', 'companycashtag go', 'companycashtag going', 'companycashtag good', 'companycashtag got', 'companycashtag great', 'companycashtag green', 'companycashtag ha', 'companycashtag have', 'companycashtag here', 'companycashtag holding', 'companycashtag hope', 'companycashtag how', 'companycashtag icahn', 'companycashtag if', 'companycashtag im', 'companycashtag in', 'companycashtag iphone', 'companycashtag is', 'companycashtag it', 'companycashtag just', 'companycashtag keep', 'companycashtag last', 'companycashtag let', 'companycashtag like', 'companycashtag lol', 'companycashtag long', 'companycashtag look', 'companycashtag looking', 'companycashtag lot', 'companycashtag love', 'companycashtag market', 'companycashtag may', 'companycashtag might', 'companycashtag more', 'companycashtag moving', 'companycashtag my', 'companycashtag need', 'companycashtag new', 'companycashtag next', 'companycashtag nice', 'companycashtag no', 'companycashtag not', 'companycashtag now', 'companycashtag numbertag', 'companycashtag oh', 'companycashtag ok', 'companycashtag on', 'companycashtag one', 'companycashtag only', 'companycashtag or', 'companycashtag out', 'companycashtag over', 'companycashtag price', 'companycashtag put', 'companycashtag really', 'companycashtag see', 'companycashtag sell', 'companycashtag sentiment', 'companycashtag short', 'companycashtag should', 'companycashtag so', 'companycashtag sold', 'companycashtag some', 'companycashtag still', 'companycashtag stock', 'companycashtag strong', 'companycashtag that', 'companycashtag there', 'companycashtag they', 'companycashtag think', 'companycashtag this', 'companycashtag time', 'companycashtag to', 'companycashtag today', 'companycashtag too', 'companycashtag up', 'companycashtag urltag', 'companycashtag usernametag', 'companycashtag very', 'companycashtag wa', 'companycashtag want', 'companycashtag watch', 'companycashtag we', 'companycashtag weekly', 'companycashtag well', 'companycashtag what', 'companycashtag when', 'companycashtag where', 'companycashtag who', 'companycashtag why', 'companycashtag will', 'companycashtag with', 'companycashtag would', 'companycashtag wow', 'companycashtag yes', 'companycashtag you', 'companynametag', 'companynametag companycashtag', 'companynametag is', 'companynametag to', 'companynametag urltag', 'companynametag will', 'companytickertag', 'companytickertag is', 'companytickertag numbertag', 'companytickertag urltag', 'companytickertag will', 'compared', 'competition', 'complete', 'conference', 'confirm', 'confirmation', 'confirmed', 'congrats', 'consensus', 'consider', 'consolidating', 'consolidation', 'consumer', 'content', 'continuation', 'continue', 'continue to', 'continues', 'continues to', 'contract', 'control', 'cook', 'cool', 'core', 'correct', 'correction', 'cost', 'could', 'could be', 'could see', 'couple', 'course', 'court', 'cover', 'covered', 'covering', 'cramer', 'crap', 'crash', 'crazy', 'credit', 'cross', 'cup', 'current', 'currently', 'customer', 'cut', 'daily', 'daily chart', 'damn', 'data', 'date', 'day', 'day and', 'day for', 'day in', 'day numbertag', 'day of', 'day to', 'day trade', 'day urltag', 'dead', 'deal', 'deal with', 'death', 'debt', 'dec', 'dec numbertag', 'december', 'decent', 'decision', 'decline', 'definitely', 'demand', 'despite', 'device', 'did', 'did not', 'didnt', 'different', 'dip', 'direction', 'discount', 'div', 'divergence', 'dividend', 'dividend aristocrat', 'dma', 'do', 'do it', 'do not', 'do you', 'doe', 'doe not', 'doesnt', 'dog', 'doing', 'dollar', 'done', 'dont', 'dont be', 'dont get', 'dont know', 'dont think', 'double', 'double bottom', 'doubt', 'dow', 'down', 'down numbertag', 'down to', 'downgrade', 'downside', 'downtrend', 'drive', 'drop', 'dropped', 'dropping', 'drug', 'due', 'due to', 'dump', 'during', 'each', 'earlier', 'early', 'earning', 'earnings', 'easily', 'easy', 'economy', 'effect', 'either', 'else', 'em', 'ema', 'emojipostag', 'emojipostag urltag', 'end', 'end of', 'energy', 'engulfing', 'enjoy', 'enough', 'enter', 'entry', 'entry point', 'eod', 'eoy', 'eps', 'equity', 'er', 'especially', 'est', 'estimate', 'etc', 'even', 'event', 'ever', 'every', 'everyone', 'everything', 'ex', 'exactly', 'excellent', 'exit', 'expect', 'expectation', 'expected', 'expecting', 'expensive', 'extremely', 'eye', 'eye on', 'face', 'fact', 'fade', 'fail', 'failed', 'fair', 'fake', 'fall', 'falling', 'far', 'fast', 'favorite', 'fb', 'fear', 'featuring', 'featuring cashtag', 'feb', 'feb numbertag', 'fed', 'feel', 'feel like', 'feeling', 'fell', 'few', 'few day', 'few week', 'fib', 'fibline', 'fight', 'figure', 'fill', 'filled', 'finally', 'financial', 'financials', 'find', 'fine', 'finish', 'finsents', 'finsents numbertag', 'fire', 'firm', 'first', 'firstquartertag', 'flag', 'flat', 'flow', 'flush', 'fly', 'focus', 'folk', 'follow', 'following', 'fool', 'for', 'for all', 'for big', 'for breakout', 'for cashtag', 'for companycashtag', 'for companynametag', 'for companytickertag', 'for day', 'for it', 'for long', 'for me', 'for more', 'for new', 'for next', 'for now', 'for numbertag', 'for short', 'for some', 'for sure', 'for this', 'for today', 'for tomorrow', 'for week', 'for year', 'ford', 'forecast', 'forget', 'forming', 'forward', 'fourthquartertag', 'free', 'fri', 'friday', 'friend', 'from', 'from cashtag', 'from companycashtag', 'from here', 'from numbertag', 'from urltag', 'fuel', 'full', 'fun', 'fund', 'fundamental', 'funny', 'further', 'future', 'gain', 'game', 'gap', 'gap fill', 'gap up', 'gas', 'gave', 'get', 'get back', 'get in', 'get it', 'get numbertag', 'get out', 'get ready', 'get to', 'getting', 'gift', 'give', 'given', 'giving', 'gl', 'glad', 'glass', 'global', 'go', 'go back', 'go down', 'go higher', 'go long', 'go to', 'go up', 'god', 'going', 'going down', 'going higher', 'going into', 'going on', 'going to', 'going up', 'gold', 'golden', 'goldman', 'gone', 'gonna', 'gonna be', 'good', 'good day', 'good for', 'good luck', 'good news', 'good to', 'goog', 'google', 'got', 'gotta', 'great', 'green', 'group', 'grow', 'growing', 'growth', 'guess', 'guidance', 'guy', 'ha', 'ha been', 'ha numbertag', 'ha to', 'had', 'haha', 'half', 'hammer', 'hand', 'handle', 'happen', 'happened', 'happening', 'happens', 'happy', 'hard', 'hard to', 'hate', 'have', 'have been', 'have numbertag', 'have to', 'havent', 'having', 'he', 'head', 'headed', 'heading', 'healthy', 'hear', 'heard', 'heavy', 'hedge', 'held', 'hell', 'help', 'her', 'here', 'here come', 'here is', 'here numbertag', 'here urltag', 'here we', 'hey', 'high', 'high and', 'high numbertag', 'high urltag', 'higher', 'him', 'his', 'history', 'hit', 'hit numbertag', 'hitting', 'hmm', 'hod', 'hold', 'hold numbertag', 'holder', 'holding', 'holding numbertag', 'holding up', 'holiday', 'home', 'home sale', 'hope', 'hope you', 'hopefully', 'hoping', 'hot', 'hour', 'house', 'housing', 'how', 'how many', 'how much', 'how to', 'hr', 'huge', 'hurt', 'icahn', 'id', 'idea', 'if', 'if cashtag', 'if companycashtag', 'if it', 'if they', 'if this', 'if we', 'if you', 'ill', 'im', 'im long', 'im not', 'image', 'image urltag', 'imagine', 'imho', 'imo', 'important', 'impressive', 'in', 'in at', 'in cashtag', 'in china', 'in companycashtag', 'in for', 'in it', 'in last', 'in market', 'in my', 'in next', 'in numbertag', 'in on', 'in this', 'inc', 'income', 'increase', 'increased', 'index', 'indicator', 'industry', 'infotrie', 'infotrie finsents', 'initial', 'innovation', 'inside', 'insider', 'instead', 'instead of', 'institution', 'institutional', 'interest', 'interesting', 'internet', 'into', 'into close', 'into earnings', 'into numbertag', 'intraday', 'intrinsic', 'intrinsic value', 'invest', 'investing', 'investment', 'investor', 'io', 'io numbertag', 'ip', 'ipad', 'ipads', 'iphone', 'iphone numbertag', 'iphones', 'ipo', 'is', 'is about', 'is buy', 'is coming', 'is companycashtag', 'is down', 'is going', 'is gonna', 'is good', 'is great', 'is in', 'is it', 'is just', 'is my', 'is next', 'is no', 'is not', 'is now', 'is numbertag', 'is on', 'is one', 'is only', 'is over', 'is so', 'is still', 'is that', 'is this', 'is to', 'is up', 'is very', 'is what', 'ish', 'isnt', 'issue', 'it', 'it all', 'it break', 'it can', 'it down', 'it go', 'it going', 'it ha', 'it is', 'it just', 'it look', 'it not', 'it numbertag', 'it time', 'it to', 'it up', 'it wa', 'it will', 'it would', 'ive', 'iwatch', 'jan', 'jan numbertag', 'january', 'job', 'join', 'joke', 'july', 'july numbertag', 'jump', 'june', 'june numbertag', 'just', 'just bought', 'just like', 'keep', 'keeping', 'key', 'kid', 'kind', 'know', 'know what', 'large', 'largest', 'last', 'last month', 'last numbertag', 'last time', 'last week', 'last year', 'late', 'later', 'latest', 'launch', 'le', 'le than', 'lead', 'leader', 'leading', 'learn', 'least', 'least numbertag', 'left', 'leg', 'let', 'let go', 'let see', 'level', 'life', 'light', 'like', 'like cashtag', 'like companycashtag', 'like it', 'like numbertag', 'like this', 'like to', 'likely', 'line', 'link', 'list', 'list for', 'list of', 'listen', 'little', 'live', 'load', 'load up', 'loaded', 'lod', 'lol', 'long', 'long and', 'long cashtag', 'long companycashtag', 'long numbertag', 'long on', 'long position', 'long setup', 'long term', 'long time', 'longer', 'longs', 'look', 'look at', 'look for', 'look good', 'look like', 'look to', 'looking', 'looking at', 'looking for', 'looking good', 'looking to', 'lose', 'loser', 'losing', 'loss', 'lost', 'lot', 'lot of', 'love', 'love it', 'love to', 'low', 'low numbertag', 'low volume', 'lower', 'lt', 'luck', 'lunch', 'ma', 'mac', 'macd', 'machine', 'made', 'major', 'make', 'make it', 'make money', 'making', 'man', 'management', 'manipulation', 'many', 'mar', 'march', 'margin', 'mark', 'market', 'market cap', 'market is', 'market share', 'market urltag', 'massive', 'matter', 'max', 'may', 'may be', 'may numbertag', 'maybe', 'me', 'mean', 'median', 'median target', 'medium', 'meeting', 'mention', 'mentioned', 'mid', 'might', 'might be', 'mil', 'million', 'min', 'min chart', 'mind', 'mini', 'minute', 'miss', 'missed', 'mkt', 'mm', 'mobile', 'mode', 'model', 'moment', 'momentum', 'momo', 'mon', 'monday', 'money', 'monster', 'month', 'month urltag', 'monthly', 'moon', 'more', 'more than', 'more to', 'more urltag', 'morning', 'mortgage', 'most', 'move', 'move higher', 'move to', 'move up', 'movement', 'moving', 'moving average', 'mr', 'much', 'much higher', 'multi', 'multiple', 'must', 'must be', 'my', 'my call', 'my companycashtag', 'my numbertag', 'my position', 'my short', 'name', 'nasdaq', 'nd', 'near', 'near numbertag', 'need', 'need to', 'needed', 'negative', 'net', 'never', 'new', 'new high', 'new numbertag', 'new product', 'news', 'next', 'next few', 'next numbertag', 'next stop', 'next week', 'next year', 'nice', 'nice move', 'nicely', 'night', 'no', 'no brainer', 'no one', 'no position', 'no reason', 'non', 'north', 'not', 'not be', 'not good', 'not sure', 'not to', 'note', 'nothing', 'nov', 'nov numbertag', 'now', 'now cashtag', 'now it', 'now numbertag', 'now urltag', 'number', 'numbertag', 'numbertag after', 'numbertag again', 'numbertag all', 'numbertag am', 'numbertag analyst', 'numbertag and', 'numbertag are', 'numbertag area', 'numbertag at', 'numbertag before', 'numbertag billion', 'numbertag buck', 'numbertag but', 'numbertag buy', 'numbertag by', 'numbertag call', 'numbertag cashtag', 'numbertag cent', 'numbertag close', 'numbertag coming', 'numbertag companycashtag', 'numbertag companynametag', 'numbertag companytickertag', 'numbertag day', 'numbertag dma', 'numbertag ema', 'numbertag emojipostag', 'numbertag eod', 'numbertag eps', 'numbertag for', 'numbertag from', 'numbertag gain', 'numbertag here', 'numbertag hour', 'numbertag if', 'numbertag in', 'numbertag is', 'numbertag ish', 'numbertag it', 'numbertag just', 'numbertag last', 'numbertag let', 'numbertag level', 'numbertag long', 'numbertag look', 'numbertag ma', 'numbertag mil', 'numbertag million', 'numbertag min', 'numbertag minute', 'numbertag month', 'numbertag more', 'numbertag nd', 'numbertag new', 'numbertag next', 'numbertag no', 'numbertag not', 'numbertag nov', 'numbertag now', 'numbertag numbertag', 'numbertag oct', 'numbertag of', 'numbertag on', 'numbertag or', 'numbertag per', 'numbertag pm', 'numbertag point', 'numbertag price', 'numbertag profit', 'numbertag pt', 'numbertag put', 'numbertag range', 'numbertag share', 'numbertag short', 'numbertag since', 'numbertag sma', 'numbertag so', 'numbertag soon', 'numbertag st', 'numbertag still', 'numbertag stock', 'numbertag stop', 'numbertag strike', 'numbertag support', 'numbertag target', 'numbertag th', 'numbertag then', 'numbertag this', 'numbertag time', 'numbertag to', 'numbertag today', 'numbertag tomorrow', 'numbertag up', 'numbertag urltag', 'numbertag view', 'numbertag wa', 'numbertag we', 'numbertag week', 'numbertag weekly', 'numbertag will', 'numbertag with', 'numbertag would', 'numbertag year', 'numbertag yr', 'obvious', 'oct', 'oct numbertag', 'october', 'of', 'of all', 'of cashtag', 'of companycashtag', 'of companynametag', 'of course', 'of day', 'of it', 'of my', 'of numbertag', 'of open', 'of stock', 'of this', 'of time', 'of week', 'of year', 'off', 'off numbertag', 'offer', 'oh', 'oi', 'oil', 'ok', 'old', 'on', 'on cashtag', 'on cnbc', 'on companycashtag', 'on companynametag', 'on companytickertag', 'on daily', 'on dip', 'on earnings', 'on friday', 'on it', 'on monday', 'on my', 'on numbertag', 'on this', 'on way', 'on weekly', 'on your', 'once', 'one', 'one day', 'one of', 'online', 'only', 'only numbertag', 'open', 'open position', 'opened', 'opening', 'opex', 'opinion', 'opportunity', 'option', 'or', 'or cashtag', 'or companycashtag', 'or numbertag', 'order', 'other', 'others', 'our', 'out', 'out for', 'out numbertag', 'out of', 'out on', 'out there', 'outlook', 'outperform', 'over', 'over next', 'over numbertag', 'overall', 'overbought', 'overnight', 'oversold', 'own', 'paid', 'pain', 'panic', 'part', 'part of', 'partner', 'partnership', 'party', 'past', 'past numbertag', 'patent', 'patience', 'patient', 'pattern', 'pay', 'paying', 'payment', 'pe', 'people', 'people are', 'per', 'perfect', 'performance', 'period', 'phone', 'pick', 'picked', 'picked up', 'picture', 'pin', 'pivot', 'place', 'plan', 'play', 'player', 'playing', 'please', 'plenty', 'plug', 'plus', 'pm', 'po', 'point', 'poised', 'pop', 'portfolio', 'position', 'position in', 'position stock', 'positive', 'positive median', 'possible', 'post', 'posted', 'potential', 'power', 'ppl', 'pre', 'pre market', 'predict', 'prediction', 'premarket', 'premium', 'pressure', 'pretty', 'previous', 'price', 'price action', 'price numbertag', 'price target', 'priced', 'prime', 'print', 'prior', 'pro', 'probably', 'problem', 'product', 'production', 'profit', 'profit taking', 'profitable', 'pt', 'pt numbertag', 'pull', 'pull back', 'pullback', 'pump', 'purchase', 'push', 'pushing', 'put', 'put for', 'put numbertag', 'qnx', 'qtr', 'quality', 'quarter', 'question', 'quick', 'quickly', 'quite', 'raise', 'raised', 'rally', 'range', 'rate', 'rather', 'rating', 'rating in', 'ratio', 'rd', 're', 'reach', 'reaction', 'read', 'ready', 'ready for', 'ready to', 'real', 'really', 'reason', 'reason to', 'rebound', 'recent', 'recently', 'record', 'recovery', 'red', 'relative', 'release', 'remain', 'remains', 'remember', 'repeat', 'report', 'reported', 'research', 'resistance', 'rest', 'rest of', 'result', 'retail', 'retest', 'return', 'rev', 'revenue', 'reversal', 'reverse', 'review', 'review of', 'reward', 'ride', 'right', 'right now', 'rip', 'rise', 'rising', 'risk', 'rock', 'roll', 'room', 'room to', 'rsi', 'rt', 'rule', 'rumor', 'run', 'run to', 'run up', 'running', 'safe', 'said', 'sale', 'same', 'samsung', 'sapphire', 'save', 'saw', 'say', 'say it', 'saying', 'screen', 'search', 'season', 'second', 'secondquartertag', 'sector', 'security', 'see', 'see companycashtag', 'see how', 'see if', 'see it', 'see numbertag', 'see this', 'see what', 'see you', 'seeing', 'seem', 'seems', 'seems like', 'seems to', 'seen', 'sell', 'sell numbertag', 'sell off', 'seller', 'selling', 'selloff', 'sense', 'sentiment', 'sentiment sp', 'sep', 'sep numbertag', 'sept', 'sept numbertag', 'september', 'serious', 'seriously', 'service', 'set', 'set up', 'setting', 'setting up', 'setup', 'setup urltag', 'sh', 'shake', 'share', 'share at', 'share numbertag', 'share of', 'shareholder', 'she', 'short', 'short cashtag', 'short companycashtag', 'short numbertag', 'short position', 'short setup', 'short term', 'short this', 'shorted', 'shorting', 'should', 'should be', 'should have', 'shoulder', 'show', 'showing', 'side', 'sign', 'signal', 'signal for', 'similar', 'simple', 'since', 'since numbertag', 'sitting', 'slow', 'slowly', 'sma', 'small', 'smart', 'smartphone', 'so', 'so far', 'so many', 'so much', 'software', 'sold', 'sold numbertag', 'solid', 'some', 'some companycashtag', 'some more', 'some of', 'someone', 'something', 'soon', 'soon urltag', 'sorry', 'sound', 'sp', 'sp numbertag', 'space', 'spike', 'split', 'spot', 'spread', 'squeeze', 'st', 'stake', 'star', 'start', 'start to', 'started', 'starting', 'starting to', 'stay', 'staying', 'steady', 'step', 'steve', 'still', 'still bullish', 'still holding', 'still in', 'still long', 'stock', 'stock and', 'stock are', 'stock cashtag', 'stock for', 'stock in', 'stock is', 'stock market', 'stock numbertag', 'stock price', 'stock that', 'stock to', 'stock urltag', 'stock will', 'stocktwits', 'stop', 'stop numbertag', 'stopped', 'store', 'story', 'straight', 'strategy', 'stream', 'street', 'strength', 'strike', 'strong', 'strong buy', 'stuff', 'stupid', 'sub', 'such', 'suck', 'summer', 'super', 'supply', 'support', 'support at', 'sure', 'surprise', 'surprised', 'sweet', 'swing', 'system', 'tablet', 'take', 'take it', 'take out', 'taken', 'taking', 'talk', 'talking', 'tank', 'taper', 'tapering', 'target', 'target numbertag', 'tax', 'tc', 'tech', 'tech stock', 'technical', 'technology', 'tell', 'telling', 'term', 'tesla', 'test', 'test numbertag', 'testing', 'tgt', 'th', 'than', 'than numbertag', 'thank', 'thank you', 'thanks', 'that', 'that companycashtag', 'that is', 'that it', 'that numbertag', 'that wa', 'that will', 'thats', 'their', 'them', 'then', 'then numbertag', 'there', 'there are', 'there is', 'these', 'these level', 'they', 'they are', 'they can', 'they have', 'they will', 'theyre', 'thing', 'think', 'think companycashtag', 'think it', 'think this', 'think we', 'thinking', 'thirdquartertag', 'this', 'this am', 'this company', 'this is', 'this market', 'this morning', 'this numbertag', 'this one', 'this stock', 'this thing', 'this time', 'this to', 'this wa', 'this week', 'this will', 'this year', 'those', 'though', 'thought', 'three', 'through', 'through numbertag', 'thru', 'thursday', 'tight', 'til', 'till', 'tim', 'tim cook', 'time', 'time for', 'time high', 'time to', 'to', 'to add', 'to all', 'to be', 'to break', 'to buy', 'to cashtag', 'to close', 'to come', 'to companycashtag', 'to cover', 'to do', 'to fill', 'to get', 'to go', 'to have', 'to hold', 'to it', 'to keep', 'to look', 'to make', 'to me', 'to move', 'to my', 'to new', 'to numbertag', 'to open', 'to pay', 'to run', 'to say', 'to see', 'to sell', 'to short', 'to start', 'to take', 'to test', 'to trade', 'to upside', 'to watch', 'today', 'today and', 'today cashtag', 'today companycashtag', 'today is', 'today numbertag', 'today on', 'today urltag', 'told', 'told you', 'tomorrow', 'tomorrow cashtag', 'ton', 'tonight', 'too', 'too much', 'took', 'top', 'top numbertag', 'total', 'touch', 'towards', 'track', 'trade', 'traded', 'trader', 'trading', 'train', 'trap', 'trend', 'trend line', 'trending', 'triangle', 'trigger', 'triple', 'true', 'trust', 'try', 'try to', 'trying', 'trying to', 'tuesday', 'turn', 'turning', 'tv', 'tweet', 'twitter', 'two', 'ugly', 'under', 'under numbertag', 'understand', 'undervalued', 'unless', 'until', 'up', 'up and', 'up cashtag', 'up for', 'up from', 'up in', 'up numbertag', 'up on', 'up to', 'up today', 'up urltag', 'up with', 'update', 'updated', 'upgrade', 'upgraded', 'ups', 'upside', 'uptrend', 'upward', 'ur', 'urltag', 'urltag cashtag', 'urltag companycashtag', 'urltag featuring', 'urltag from', 'urltag image', 'urltag urltag', 'urltag via', 'usa', 'use', 'used', 'user', 'usernametag', 'usernametag cashtag', 'usernametag companycashtag', 'usernametag it', 'usernametag numbertag', 'usernametag urltag', 'usernametag usernametag', 'usernametag you', 'using', 'usually', 'valuation', 'value', 'very', 'very bullish', 'very good', 'very soon', 'very strong', 'via', 'via urltag', 'via usernametag', 'video', 'view', 'view here', 'vol', 'volatility', 'volume', 'wa', 'wa numbertag', 'wait', 'wait for', 'waiting', 'waiting for', 'wall', 'wall st', 'wall street', 'wanna', 'want', 'want numbertag', 'want to', 'wanted', 'war', 'wasnt', 'watch', 'watch cashtag', 'watch for', 'watch list', 'watch urltag', 'watching', 'watchlist', 'wave', 'way', 'way to', 'we', 'we are', 'we can', 'we get', 'we go', 'we have', 'we need', 'we see', 'we should', 'we will', 'weak', 'weakness', 'wed', 'wedge', 'wednesday', 'week', 'week cashtag', 'week high', 'week numbertag', 'week urltag', 'weekend', 'weekly', 'weekly call', 'weekly chart', 'weekly numbertag', 'well', 'went', 'were', 'what', 'what do', 'what is', 'what you', 'whats', 'when', 'when companycashtag', 'when it', 'when they', 'when you', 'where', 'which', 'which is', 'while', 'who', 'who is', 'whole', 'why', 'why is', 'will', 'will be', 'will buy', 'will continue', 'will get', 'will go', 'will have', 'will it', 'will make', 'will not', 'will see', 'will sell', 'will take', 'win', 'window', 'winner', 'wish', 'with', 'with cashtag', 'with companycashtag', 'with it', 'with numbertag', 'with this', 'within', 'without', 'wk', 'wonder', 'wont', 'word', 'work', 'working', 'world', 'worry', 'worst', 'worth', 'would', 'would be', 'would have', 'wouldnt', 'wow', 'wrong', 'wsj', 'wwdc', 'ya', 'yeah', 'year', 'year ago', 'year urltag', 'yes', 'yesterday', 'yet', 'yield', 'you', 'you are', 'you can', 'you dont', 'you guy', 'you have', 'you know', 'you should', 'you think', 'you want', 'you will', 'youll', 'your', 'your own', 'youre', 'yr', 'zero', 'zone']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer_bow.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TF-IDF: transform the count matrix to tf-idf values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_tfidf = TfidfTransformer()\n",
    "X_tfidf_train = vectorizer_tfidf.fit_transform(X_bow_train)\n",
    "X_tfidf_test = vectorizer_tfidf.transform(X_bow_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training\n",
    "## Logistic regression\n",
    "Train logistic regression using the vectorized features.\n",
    "* Bag-of-words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_bow_cv = LogisticRegressionCV(random_state=0, max_iter=2000, cv=5, Cs=20, scoring='f1').fit(X_bow_train, y_train.flatten())\n",
    "y_logistic_bow_test = logistic_bow_cv.predict(X_bow_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TF-IDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_tfidf_cv = LogisticRegressionCV(random_state=0, max_iter=2000, cv=5, Cs=20, scoring='f1').fit(X_tfidf_train, y_train.flatten())\n",
    "y_logistic_tfidf_test = logistic_tfidf_cv.predict(X_tfidf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "Define function for dividing iterable into chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks(iterable, chunk_size):\n",
    "    size = iterable.shape[0]\n",
    "    if size < chunk_size:\n",
    "        yield iterable\n",
    "    chunks_nb = int(size / chunk_size)\n",
    "    iter_ints = range(0, chunks_nb)\n",
    "    for i in iter_ints:\n",
    "        j = i * chunk_size\n",
    "        if i + 1 < chunks_nb:\n",
    "            k = j + chunk_size\n",
    "            yield iterable[j:k]\n",
    "        else:\n",
    "            yield iterable[j:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function that makes predictions with Naive Bayes by making the forecasts iteratively to avoid memory issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_GaussianNB(model, X, chunk_size):\n",
    "    y = np.empty(0)\n",
    "    for X_i in get_chunks(X, chunk_size):\n",
    "        y_i = model.predict(X_i.toarray())\n",
    "        y = np.concatenate((y, y_i))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train naive bayes classifier using the vectorized features.\n",
    "* Bag-of-words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "naivebayes_bow = MultinomialNB().fit(X_bow_train.toarray(), y_train.flatten())\n",
    "y_naivebayes_bow_test = predict_GaussianNB(naivebayes_bow, X_bow_test, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TF-IDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "naivebayes_tfidf = MultinomialNB().fit(X_tfidf_train.toarray(), y_train.flatten())\n",
    "y_naivebayes_tfidf_test = predict_GaussianNB(naivebayes_tfidf, X_tfidf_test, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation\n",
    "Create data-frame that summarises the accuracy and F1-score of the different models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Model': ['Logistic', 'Logistic', 'Naive-Bayes', 'Naive-Bayes'], 'Feature': ['BoW', 'TF-IDF', 'BoW', 'TF-IDF'], \n",
    "       'Accuracy': [accuracy_score(y_test, y_logistic_bow_test), accuracy_score(y_test, y_logistic_tfidf_test), \n",
    "                   accuracy_score(y_test, y_naivebayes_bow_test), accuracy_score(y_test, y_naivebayes_tfidf_test)], \n",
    "       'F1': [f1_score(y_test, y_logistic_bow_test), f1_score(y_test, y_logistic_tfidf_test), \n",
    "                   f1_score(y_test, y_naivebayes_bow_test), f1_score(y_test, y_naivebayes_tfidf_test)]}\n",
    "model_performance = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print evaluation of the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Model Feature  Accuracy        F1\n",
      "0     Logistic     BoW  0.785563  0.867935\n",
      "1     Logistic  TF-IDF  0.786946  0.869006\n",
      "2  Naive-Bayes     BoW  0.769542  0.853529\n",
      "3  Naive-Bayes  TF-IDF  0.765179  0.862610\n"
     ]
    }
   ],
   "source": [
    "print(model_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save models\n",
    "Define directory where the models are saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_models = \"D:/Project data/Data Project Sentiment Race/02_models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Bag-of-Words vectorizer (we need to save also this vectorizer since we use the TF-IDF transformer which needs a BoW vectorized feature matrix):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/Project data/Data Project Sentiment Race/02_models/vectorizer_bow.joblib']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(vectorizer_bow, dir_models+'vectorizer_bow.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save TF-IDF vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/Project data/Data Project Sentiment Race/02_models/vectorizer_tfidf.joblib']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(vectorizer_tfidf, dir_models+'vectorizer_tfidf.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Logistic regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/Project data/Data Project Sentiment Race/02_models/logistic_tfidf_cv.joblib']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(logistic_tfidf_cv, dir_models+'logistic_tfidf_cv.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Naive-Bayes model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/Project data/Data Project Sentiment Race/02_models/naivebayes_tfidf.joblib']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(naivebayes_tfidf, dir_models+'naivebayes_tfidf.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robustness checks\n",
    "Robustness checks are only done for the tf-idf feature matrix used with the logistic regression model, as this is clearly the best performing setting.\n",
    "## Remove Apple Inc.\n",
    "Repeat the analysis but without the tweets about Apple. Since Apple is the company with the largest amount of tweets, this robustness check, controls that the accuracy is not driven only by Apple.\n",
    "\n",
    "Define data set without Apple Tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_id = 'D8442A'\n",
    "data_tweets_no_apple = data_tweets[data_tweets.rpid!=apple_id]\n",
    "idx_train_no_apple = data_tweets_no_apple['tweet_date_ET'].map(lambda x: x in training_date_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize text to create the feature matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_tfidf_no_apple = TfidfVectorizer(stop_words=['a', 'an', 'the'], min_df=0.001, ngram_range=(1, 1))\n",
    "X_tfidf_no_apple_train = vectorizer_tfidf_no_apple.fit_transform(data_tweets_no_apple.loc[idx_train_no_apple, 'text'])\n",
    "X_tfidf_no_apple_test = vectorizer_tfidf_no_apple.transform(data_tweets_no_apple.loc[~idx_train_no_apple, 'text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define target variables without Apple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_no_apple_train = lb.fit_transform(data_tweets_no_apple.loc[idx_train_no_apple, 'StockTwits_sentiment'])\n",
    "y_no_apple_test = lb.transform(data_tweets_no_apple.loc[~idx_train_no_apple, 'StockTwits_sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate the logistic model without Apple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_tfidf_no_apple_cv = LogisticRegressionCV(random_state=0, max_iter=2000, cv=5, Cs=20, scoring='f1').fit(X_tfidf_no_apple_train, y_no_apple_train.flatten())\n",
    "y_logistic_tfidf_no_apple_test = logistic_tfidf_no_apple_cv.predict(X_tfidf_no_apple_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute accuracy of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7822233087987649\n",
      "0.8633259916703908\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_no_apple_test, y_logistic_tfidf_no_apple_test))\n",
    "print(f1_score(y_no_apple_test, y_logistic_tfidf_no_apple_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only uni-grams\n",
    "Consider only uni-grams when defining the feature matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_tfidf_uni = TfidfVectorizer(stop_words=['a', 'an', 'the'], min_df=0.001, ngram_range=(1, 1))\n",
    "X_tfidf_uni_train = vectorizer_tfidf_uni.fit_transform(data_tweets.loc[idx_train, 'text'])\n",
    "X_tfidf_uni_test = vectorizer_tfidf_uni.transform(data_tweets.loc[~idx_train, 'text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the logistic model with the unigrams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_tfidf_uni_cv = LogisticRegressionCV(random_state=0, max_iter=2000, cv=5, Cs=20, scoring='f1').fit(X_tfidf_uni_train, y_train.flatten())\n",
    "y_logistic_tfidf_uni_test = logistic_tfidf_uni_cv.predict(X_tfidf_uni_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of the logistic model trained on uni-grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7838767356063683\n",
      "0.8668061459006281\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_logistic_tfidf_uni_test))\n",
    "print(f1_score(y_test, y_logistic_tfidf_uni_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}